{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "from utils import *\n",
    "import os\n",
    "\n",
    "# Ensure we're running in the right directory\n",
    "chdir_this_file()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "# Import data\n",
    "df = pd.DataFrame(json.load(open(\"../../public/data/local/countries_processed.json\", encoding=\"utf-8\")))\n",
    "\n",
    "# Filter & rename columns\n",
    "df.columns = ['iso', 'iso3', 'iso_numeric', 'fips', 'name', 'capital',\n",
    "              'area_km2', 'population', 'continent', 'tld',\n",
    "              'currency_code', 'currency_name', 'phone', 'zip_format', 'zip_regex',\n",
    "              'languages', 'geonameid', 'neighbors', 'eq_fips', 'parent', 'territories', 'neighbors_t']\n",
    "\n",
    "subset = ['iso', 'iso3', 'name', 'capital', 'continent',\n",
    "          'area_km2', 'population',\n",
    "          'currency_code', 'currency_name', 'languages',\n",
    "          'territories', 'neighbors', 'neighbors_t']\n",
    "df = df[subset]\n",
    "\n",
    "# Import GDP data\n",
    "# GDP data from https://github.com/datasets/gdp/blob/master/data/gdp.csv\n",
    "gdp_data = pd.read_csv(\"../../public/data/local/gdp.csv\")\n",
    "gdp = gdp_data.sort_values(\"Year\").groupby(\"Country Code\").tail(1).set_index(\"Country Code\").rename(columns={\"Value\": \"gdp\"})\n",
    "df = df.join(gdp[\"gdp\"], on=\"iso3\")\n",
    "# print(\"no gdp data:\")\n",
    "# print(df[df[\"gdp\"].isna()][[\"iso\", \"name\", \"population\", \"gdp\"]])\n",
    "df.loc[df.iso == \"TW\", \"gdp\"] = 790.7e9  # https://en.wikipedia.org/wiki/Economy_of_Taiwan (2023 data, accessed Aug 2023)\n",
    "df.loc[df.iso == \"KP\", \"gdp\"] = 28.5e9  # https://en.wikipedia.org/wiki/Economy_of_North_Korea (2016 data, accessed Aug 2023)\n",
    "df[\"gdp_per_capita\"] = df[\"gdp\"] / df[\"population\"]\n",
    "df.loc[df.iso == \"VA\", \"gdp_per_capita\"] = 21198  #  https://en.wikipedia.org/wiki/Economy_of_Vatican_City (2016 data, accessed Aug 2023)\n",
    "df[\"gdp\"] = df[\"gdp_per_capita\"] * df[\"population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom data changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual fixes\n",
    "df.loc[df[\"name\"] == \"Palau\", \"capital\"] = \"Ngerulmud\"  # old value seems wrong\n",
    "\n",
    "# Consider territorial borders as alternative values (e.g. France-Brazil)\n",
    "neighbors_alt = df.apply(lambda row: [c for c in row[\"neighbors_t\"] if c not in row[\"neighbors\"]], axis=1)\n",
    "df.drop(columns=[\"neighbors_t\"], inplace=True)\n",
    "df.insert(list(df.columns).index(\"neighbors\") + 1, \"neighbors_alt\", neighbors_alt)\n",
    "\n",
    "# Border fixes\n",
    "remove_border(df, \"US\", \"Cuba\")  # not so narrow maritime border\n",
    "remove_border(df, \"US\", \"Bahamas\")  # not so narrow maritime border\n",
    "add_alternative_border(df, \"Singapore\", \"Malaysia\")  # narrow maritime border\n",
    "add_alternative_border(df, \"Spain\", \"Morocco\")  # Ceuta/Melilla provinces\n",
    "\n",
    "# Additional columns & global fixes\n",
    "df[\"continent\"].fillna(\"NA\", inplace=True)  # North America fix\n",
    "df[\"landlocked\"] = df[\"iso\"].isin(\"AF,AD,AM,AT,AZ,BY,BT,BO,BW,BF,BI,CF,TD,CZ,SZ,ET,HU,KZ,XK,KG,LA,LS,LI,LU,MW,ML,MD,MN,NP,NE,MK,PY,RW,SM,RS,SK,SS,CH,TJ,TM,UG,UZ,VA,ZM,ZW\".split(\",\"))\n",
    "df[\"island\"] = (df[\"neighbors\"].apply(len) == 0) | df[\"iso\"].isin(\"ID,PG,TL,SG,BN,GB,IE,DO,HT\".split(\",\"))\n",
    "add_alternative_value(df, \"island\", \"Australia\", False, True)\n",
    "df[\"capital_not_largest\"] = df[\"iso\"].isin(\n",
    "    \"AU,BZ,BJ,BO,BR,BI,CM,CA,CN,EC,GQ,GM,IN,IL,CI,KZ,LI,FM,MT,MA,MM,NZ,NG,PK,PW,PH,SM,ZA,LK,CH,TW,TZ,TT,TR,AE,US,VN\".split(\n",
    "        \",\"\n",
    "    )\n",
    ")  # https://en.wikipedia.org/wiki/List_of_countries_whose_capital_is_not_their_largest_city (2024-11-21)\n",
    "add_alternative_value(df, \"capital_not_largest\", \"Israel\", True, False)\n",
    "\n",
    "\n",
    "# Alternative values\n",
    "# Names\n",
    "add_alternative_value(df, \"name\", \"CI\", \"Ivory Coast\", \"Côte d'Ivoire\")\n",
    "add_alternative_value(df, \"name\", \"CN\", \"China\", \"People's Republic of China\")\n",
    "add_alternative_value(df, \"name\", \"MK\", \"North Macedonia\", \"Macedonia\")\n",
    "add_alternative_value(df, \"name\", \"PS\", \"Palestine\", \"Palestinian Territory\")\n",
    "add_alternative_value(df, \"name\", \"TR\", \"Türkiye\", \"Turkey\")\n",
    "add_alternative_value(df, \"name\", \"TW\", \"Taiwan\", \"Republic of China\")\n",
    "add_alternative_value(df, \"name\", \"VA\", \"Vatican\", \"Vatican City\")\n",
    "add_alternative_value(df, \"name\", \"US\", \"United States\", \"United States of America\", \"USA\")\n",
    "add_alternative_value(df, \"name\", \"CZ\", \"Czech Republic\", \"Czechia\")\n",
    "add_alternative_value(df, \"name\", \"CV\", \"Cabo Verde\", \"Cape Verde\")\n",
    "\n",
    "# Multiple continents (source: https://en.wikipedia.org/wiki/List_of_transcontinental_countries)\n",
    "add_alternative_value(df, \"continent\", \"Armenia\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Georgia\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Azerbaijan\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Trinidad and Tobago\", \"NA\", \"SA\")\n",
    "add_alternative_value(df, \"continent\", \"Panama\", \"NA\", \"SA\")\n",
    "add_alternative_value(df, \"continent\", \"Egypt\", \"AF\", \"AS\")\n",
    "add_alternative_value(df, \"continent\", \"Russia\", \"EU\", \"AS\")\n",
    "add_alternative_value(df, \"continent\", \"TR\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Timor Leste\", \"AS\", \"OC\")\n",
    "\n",
    "# Borders\n",
    "add_alternative_value(df, \"name\", \"CI\", \"Ivory Coast\", \"Côte d'Ivoire\")\n",
    "\n",
    "# Multiple/unclear capital (source: https://en.wikipedia.org/wiki/List_of_countries_with_multiple_capitals)\n",
    "add_alternative_value(df, \"capital\", \"Kazakhstan\", \"Astana\", \"Nur-Sultan\")\n",
    "add_alternative_value(df, \"capital\", \"Bolivia\", \"La Paz\", \"Sucre\")\n",
    "add_alternative_value(df, \"capital\", \"Burundi\", \"Gitega\", \"Bujumbura\")\n",
    "add_alternative_value(df, \"capital\", \"CI\", \"Yamoussoukro\", \"Abidjan\")\n",
    "add_alternative_value(df, \"capital\", \"Eswatini\", \"Mbabane\", \"Lobamba\")\n",
    "add_alternative_value(df, \"capital\", \"Malaysia\", \"Kuala Lumpur\", \"Putrajaya\")\n",
    "add_alternative_value(df, \"capital\", \"Netherlands\", \"Amsterdam\", \"The Hague\")\n",
    "add_alternative_value(df, \"capital\", \"Palestine\", \"Ramallah\", \"Jerusalem\", \"East Jerusalem\")\n",
    "add_alternative_value(df, \"capital\", \"South Africa\", \"Pretoria\", \"Cape Town\", \"Bloemfontein\")\n",
    "add_alternative_value(df, \"capital\", \"Sri Lanka\", \"Colombo\", \"Sri Jayawardenepura Kotte\", \"Kotte\")\n",
    "\n",
    "# Capitals with multiple spellings / alternative names\n",
    "add_alternative_value(df, \"capital\", \"US\", \"Washington\", \"Washington, DC\")\n",
    "add_alternative_value(df, \"capital\", \"Chile\", \"Santiago\", \"Santiago de Chile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "# Import flag colors\n",
    "from colors import add_flag_colors\n",
    "df = add_flag_colors(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elevation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "elev = pd.read_csv(\"../../public/data/local/elevation/elevation.csv\", encoding=\"utf-8\", sep=\";\")\n",
    "elev.columns = [\"name\", \"max_elev_name\", \"max_elev\", \"min_elev_name\", \"min_elev\", \"elev_span\"]\n",
    "elev[\"name\"].fillna(method='ffill', inplace=True)\n",
    "elev = elev.groupby(\"name\").agg({col: list for col in elev.columns[1:]}).reset_index()\n",
    "\n",
    "def parse_name(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = unicodedata.normalize(\"NFKD\", s).strip()\n",
    "    # remove footnote\n",
    "    return re.sub(r\"\\[.*?\\]\", \"\", s)\n",
    "    \n",
    "def parse_elevation(specs):\n",
    "    for s in specs:\n",
    "        if s is None or pd.isna(s):\n",
    "            continue\n",
    "        if type(s) == str:\n",
    "            if s.lower() == \"sea level\":\n",
    "                return 0\n",
    "            if s.lower() == \"data missing\" or s.lower == \"[data missing]\":\n",
    "                return None\n",
    "            match = re.search(r\"([\\-−\\+]?[\\d\\.,]+)\\s*m\", s)\n",
    "            if match is None:\n",
    "                continue\n",
    "            return int(float(match.groups()[0].replace(\"−\", \"-\")))\n",
    "        return specs\n",
    "    return None\n",
    "def parse_elevation_name(specs):\n",
    "    for s in specs:\n",
    "        if s is None or pd.isna(s):\n",
    "            continue\n",
    "        if type(s) == str:\n",
    "            if s.lower() == \"data missing\" or s.lower == \"[data missing]\":\n",
    "                print(s)\n",
    "                return None\n",
    "            return parse_name(s)\n",
    "    return None\n",
    "elev[\"name\"] = elev[\"name\"].apply(parse_name)\n",
    "elev[\"max_elev\"] = elev[\"max_elev\"].apply(parse_elevation).astype(float)\n",
    "elev[\"max_elev_name\"] = elev[\"max_elev_name\"].apply(parse_elevation_name)\n",
    "elev[\"min_elev\"] = elev[\"min_elev\"].apply(parse_elevation).astype(float)\n",
    "elev[\"min_elev_name\"] = elev[\"min_elev_name\"].apply(parse_elevation_name)\n",
    "# elev[elev[\"min_elev_name\"].str.contains(\"data\")]\n",
    "# elev[elev[\"min_elev_name\"].apply(lambda x: x is not None and not pd.isna(x).any() and any([\"data\" in s for s in x]))]\n",
    "# elev[elev[\"min_elev_name1\"].isna()]\n",
    "elev.loc[48, \"name\"] = \"Cabo Verde\"\n",
    "elev.loc[79, \"name\"] = \"Micronesia\"\n",
    "elev.loc[220, \"name\"] = \"Sao Tome and Principe\"\n",
    "elev.loc[225, \"name\"] = \"Timor Leste\"\n",
    "elev.loc[231, \"name\"] = \"Türkiye\"\n",
    "elev.loc[252, \"name\"] = \"Vatican\"\n",
    "\n",
    "elev = elev.sort_values(\"name\").drop(columns=\"elev_span\")\n",
    "\n",
    "df = df.merge(elev, on=\"name\", how=\"left\")\n",
    "print(f\"Added elevation data ({df['max_elev'].isna().sum()} countries without data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df[\"name\"]).difference(set(elev[\"name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elev[elev.name.apply(lambda name: name in [\"Vatican City\", \"Turkey\", \"Cape Verde\"] or any(s in name for s in [\"Micro\", \"ncipe\", \"Timor\", \"Verde\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['max_elev'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all alternative values\n",
    "altcols = [col for col in df.columns if col.endswith(\"_alt\")]\n",
    "print(\"\\nAll countries with alternative values:\")\n",
    "df[df[altcols].applymap(len).sum(axis=1) > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export country data (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_country_data(df, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tictacglobe-lTsexBXT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
