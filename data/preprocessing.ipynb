{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Ambiguous continents:\n",
    "  - Timor-Leste (OC, AS)\n",
    "  - Armenia, Azerbaijan, Georgia (EU, AS)\n",
    "  - Trinidad and Tobago (NA, SA)\n",
    "\n",
    "Adding ambiguous continents should not create new cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD_SIZE = 3\n",
    "MIN_CELL_SIZE = 1\n",
    "MAX_CELL_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = json.load(open(\"data/countries_processed.json\", encoding=\"utf-8\"))\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter & rename columns\n",
    "df.columns = ['iso', 'iso3', 'iso_numeric', 'fips', 'name', 'capital',\n",
    "              'area_km2', 'population', 'continent', 'tld',\n",
    "              'currency_code', 'currency_name', 'phone', 'zip_format', 'zip_regex',\n",
    "              'languages', 'geonameid', 'neighbors', 'eq_fips', 'parent', 'territories', 'neighbors_t']\n",
    "subset = ['iso', 'name', 'capital', 'continent',\n",
    "          'area_km2', 'population',\n",
    "          'currency_code', 'currency_name', 'languages',\n",
    "          'territories', 'neighbors_t']\n",
    "df = df[subset]\n",
    "df.rename(columns={\"neighbors_t\": \"neighbors\"}, inplace=True)\n",
    "\n",
    "# Additional columns & global fixes\n",
    "df[\"continent\"].fillna(\"NA\", inplace=True)  # North America fix\n",
    "df[\"landlocked\"] = df[\"iso\"].isin(\"AF,AD,AM,AT,AZ,BY,BT,BO,BW,BF,BI,CF,TD,CZ,SZ,ET,HU,KZ,XK,LA,LS,LI,LU,MW,ML,MD,MN,NP,NE,MK,PY,RW,SM,RS,SK,SS,CH,TJ,UG,VA,ZA,ZW\".split(\",\"))\n",
    "df[\"island\"] = df[\"neighbors\"].apply(len) == 0\n",
    "\n",
    "def add_alternative_value(df, col, country, *values):\n",
    "    cols = list(df.columns)\n",
    "    if col not in cols:\n",
    "        return False\n",
    "    \n",
    "    # Add alternative column if not exists\n",
    "    altcol = col + \"_alt\"\n",
    "    if altcol not in cols:\n",
    "        df.insert(cols.index(col) + 1, altcol, df[col].apply(lambda x: []))\n",
    "    \n",
    "    # Find country\n",
    "    if country in df[\"name\"].values:\n",
    "        index = df.index[df[\"name\"] == country][0]\n",
    "    elif country in df[\"iso\"].values:\n",
    "        index = df.index[df[\"iso\"] == country][0]\n",
    "    else:\n",
    "        print(f\"country {country} not found!\")\n",
    "        return False\n",
    "    \n",
    "    # Add values\n",
    "    values = sum([[x] if not isinstance(x, list) else x for x in values], [])\n",
    "#     values = [val for val in values if val not in df.loc[index, altcol]]\n",
    "    \n",
    "    # Warn if value to-be-added is the actual value. Swap if not first-named\n",
    "    if df.loc[index, col] in values:\n",
    "        if values[0] == df.loc[index, col]:\n",
    "            print(f\"{country}/{col}: '{df.loc[index, col]}' is already set as main value - skipping\")\n",
    "        else:\n",
    "            print(f\"{country}/{col}: '{df.loc[index, col]}' is already set as main value - swapping with '{values[0]}'\")\n",
    "            df.loc[index, col] = values[0]\n",
    "        values = values[1:]\n",
    "\n",
    "    for val in values:\n",
    "        if val not in df.loc[index, altcol]:\n",
    "            df.loc[index, altcol].append(val)\n",
    "    return True\n",
    "\n",
    "# Individual fixes\n",
    "df.loc[df[\"name\"] == \"Palau\", \"capital\"] = \"Ngerulmud\"\n",
    "\n",
    "# Alternative values\n",
    "# Names\n",
    "add_alternative_value(df, \"name\", \"CI\", \"Ivory Coast\", \"Côte d'Ivoire\")\n",
    "add_alternative_value(df, \"name\", \"TR\", \"Türkiye\", \"Turkey\")\n",
    "add_alternative_value(df, \"name\", \"VA\", \"Vatican\", \"Vatican City\")\n",
    "\n",
    "# Multiple continents (source: https://en.wikipedia.org/wiki/List_of_transcontinental_countries)\n",
    "add_alternative_value(df, \"continent\", \"Armenia\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Georgia\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Azerbaijan\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Trinidad and Tobago\", \"SA\", \"NA\")\n",
    "add_alternative_value(df, \"continent\", \"Panama\", \"NA\", \"SA\")\n",
    "add_alternative_value(df, \"continent\", \"Egypt\", \"AF\", \"AS\")\n",
    "add_alternative_value(df, \"continent\", \"Russia\", \"EU\", \"AS\")\n",
    "add_alternative_value(df, \"continent\", \"TR\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Timor Leste\", \"AS\", \"OC\")\n",
    "\n",
    "# Multiple capitals (source: https://en.wikipedia.org/wiki/List_of_countries_with_multiple_capitals)\n",
    "add_alternative_value(df, \"capital\", \"Kazakhstan\", \"Astana\", \"Nur-Sultan\")\n",
    "add_alternative_value(df, \"capital\", \"Bolivia\", \"La Paz\", \"Sucre\")\n",
    "add_alternative_value(df, \"capital\", \"Burundi\", \"Gitega\", \"Bujumbura\")\n",
    "add_alternative_value(df, \"capital\", \"CI\", \"Yamoussoukro\", \"Abidjan\")\n",
    "add_alternative_value(df, \"capital\", \"Eswatini\", \"Mbabane\", \"Lobamba\")\n",
    "add_alternative_value(df, \"capital\", \"Malaysia\", \"Kuala Lumpur\", \"Putrajaya\")\n",
    "add_alternative_value(df, \"capital\", \"Netherlands\", \"Amsterdam\", \"The Hague\")\n",
    "add_alternative_value(df, \"capital\", \"South Africa\", \"Pretoria\", \"Cape Town\", \"Bloemfontein\")\n",
    "add_alternative_value(df, \"capital\", \"Sri Lanka\", \"Colombo\", \"Sri Jayawardenepura Kotte\")\n",
    "\n",
    "# Display all changes\n",
    "altcols = [col for col in df.columns if col.endswith(\"_alt\")]\n",
    "print(\"\\nAll countries with alternative values:\")\n",
    "df[df[altcols].applymap(len).sum(axis=1) > 0]\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign colors\n",
    "colors = pd.read_csv(\"data/flag-colors.csv\", sep=\";\")\n",
    "colors.columns = [\"country\", \"color\"]\n",
    "colors[\"country\"].fillna(method='ffill', inplace=True)\n",
    "colors.dropna(inplace=True)\n",
    "colors = colors.applymap(lambda x: x.strip())\n",
    "\n",
    "\n",
    "cmap = {\n",
    "    \"Light Blue\": \"Blue\",\n",
    "    \"Dark Blue\": \"Blue\",\n",
    "    \"Sky Blue\": \"Blue\",\n",
    "    \"Aquamarine Blue\": \"Blue\",\n",
    "    \"Fulvous\": \"Orange\",\n",
    "    \"Crimson\": \"Red\",\n",
    "    \"Saffron Orange\": \"Orange\",\n",
    "    \"Green Or Blue\": \"Green\",\n",
    "    \"Maroon\": \"Red\",  # Qatar, Sri Lanka,\n",
    "    \"Olive Green\": \"Green\",\n",
    "    \"Yellow\": \"Yellow/Gold\",\n",
    "    \"Gold\": \"Yellow/Gold\",\n",
    "    \"Golden\": \"Yellow/Gold\",\n",
    "}\n",
    "name_map = {\n",
    "    'American Samoa': None,\n",
    "    'Anguilla': None,\n",
    "    'Antigua And Barbuda': 'Antigua and Barbuda',\n",
    "    'Aruba': None,\n",
    "    'Bermuda': None,\n",
    "    'Bosnia And Herzegovina': 'Bosnia and Herzegovina',\n",
    "    'Bouvet Island': None,\n",
    "    'Brunei Darussalam': \"Brunei\",\n",
    "    'Cook Islands': None,\n",
    "    'Curaçao': None,\n",
    "    \"Côte D'Ivoire\": 'Ivory Coast',\n",
    "    'Democratic Republic Of The Congo': 'Democratic Republic of the Congo',\n",
    "    'French Polynesia': None,\n",
    "    'Holy See (Vatican City State)': \"Vatican\",\n",
    "    'Niue': None,\n",
    "    'Norfolk Island': None,\n",
    "    'Palestine': 'Palestinian Territory',\n",
    "    'Pitcairn Islands': None,\n",
    "    'Republic Of The Congo': 'Republic of the Congo',\n",
    "    'Russian Federation': \"Russia\",\n",
    "    'Saint Kitts And Nevis': 'Saint Kitts and Nevis',\n",
    "    'Saint Vincent And The Grenadines': 'Saint Vincent and the Grenadines',\n",
    "    'Sao Tome And Principe': 'Sao Tome and Principe',\n",
    "    'Syrian Arab Republic': \"Syria\",\n",
    "    'Tanzania, United Republic Of': \"Tanzania\",\n",
    "    'Trinidad And Tobago': 'Trinidad and Tobago',\n",
    "    'Åland Islands': None,\n",
    "    'Turkey': 'Türkiye'\n",
    "}\n",
    "add = [\n",
    "    {\"country\": \"Timor Leste\", \"color\": [\"Red\", \"Yellow/Gold\", \"Black\", \"White\"]},\n",
    "    {\"country\": \"Kosovo\", \"color\": [\"Blue\", \"Yellow/Gold\", \"White\"]},\n",
    "    {\"country\": \"Taiwan\", \"color\": [\"Red\", \"Blue\", \"White\"]}\n",
    "]\n",
    "\n",
    "colors[\"color\"] = colors[\"color\"].apply(lambda c: cmap.get(c, c))\n",
    "colors[\"country\"] = colors[\"country\"].apply(lambda x: name_map.get(x, x))\n",
    "colors1 = colors.groupby(by=\"country\")[\"color\"].agg(list).reset_index()\n",
    "colors1 = colors1.append(add, ignore_index=True)\n",
    "\n",
    "colors2 = pd.merge(df[[\"name\"]], colors1, how=\"left\", left_on=\"name\", right_on=\"country\")\n",
    "colors2_outer = pd.merge(df[[\"name\"]], colors1, how=\"outer\", left_on=\"name\", right_on=\"country\", indicator=True)\n",
    "df[\"flag_colors\"] = colors2[\"color\"]\n",
    "\n",
    "no_flag = df[\"flag_colors\"].isna().sum()\n",
    "print(f\"Assigned colors. {no_flag} countries missing a flag.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "for row in list(df.iterrows()):\n",
    "    country = row[1].to_dict()\n",
    "    print(f'{country[\"name\"]} ({country[\"iso\"]}): {\", \".join(country[\"flag_colors\"])}')\n",
    "    display(SVG(url=f'https://hatscripts.github.io/circle-flags/flags/{country[\"iso\"].lower()}.svg'))\n",
    "    print()\n",
    "# display(Image(filename=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(df[\"flag_colors\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"flag_colors\"].map(lambda x: \"Gold\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import total_ordering\n",
    "\n",
    "@total_ordering\n",
    "class Category:\n",
    "    def __init__(self, key: str, name: str, difficulty: float, values: pd.Series):\n",
    "        self.key = key\n",
    "        self.name = name\n",
    "        self.difficulty = difficulty\n",
    "        self.values = values\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.key < other.key\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.key == other.key\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.key)\n",
    "\n",
    "@total_ordering\n",
    "class NominalCategory(Category):\n",
    "    def __init__(self, key: str, name: str, difficulty: float, values: pd.Series):\n",
    "        super().__init__(key, name, difficulty, values)\n",
    "        self.sets = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"NominalCategory('{self.key}', {len(self.sets)} values)\"\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.key < other.key\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.key == other.key\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.key)\n",
    "\n",
    "@total_ordering\n",
    "class MultiNominalCategory(Category):\n",
    "    def __init__(self, key: str, name: str, difficulty: float, values: pd.Series):\n",
    "        super().__init__(key, name, difficulty, values)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"MultiNominalCategory('{self.key}', {len(self.sets)} values)\"\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.key < other.key\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.key == other.key\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.key)\n",
    "    \n",
    "        \n",
    "nominal_categories = [\n",
    "    NominalCategory(key=\"continent\", name=\"Continent\", difficulty=1, values=df[\"Continent\"]),\n",
    "    NominalCategory(key=\"starting_letter\", name=\"Starting letter\", difficulty=1, values=df[\"Country\"].apply(lambda x: x[0].upper())),\n",
    "    NominalCategory(key=\"ending_letter\", name=\"Ending letter\", difficulty=2, values=df[\"Country\"].apply(lambda x: x[-1].upper())),\n",
    "    NominalCategory(key=\"capital_starting_letter\", name=\"Capital starting letter\", difficulty=1.5, values=df[\"Capital\"].apply(lambda x: x[0].upper())),\n",
    "    NominalCategory(key=\"capital_ending_letter\", name=\"Capital ending letter\", difficulty=3, values=df[\"Capital\"].apply(lambda x: x[-1].upper())),\n",
    "    MultiNominalCategory(key=\"flag_colors\", name=\"Flag color\", difficulty=1.5, values=df[\"flag_colors\"]),\n",
    "]\n",
    "nominal_categories = {cat.key: cat for cat in nominal_categories}\n",
    "\n",
    "values = pd.concat([\n",
    "    df[[\"ISO\", \"Country\"]],\n",
    "    pd.DataFrame({cat.key: cat.values for cat in nominal_categories.values()}),\n",
    "#     pd.DataFrame(bool_categories)\n",
    "], axis=1)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in nominal_categories.values():\n",
    "    if isinstance(cat, NominalCategory):\n",
    "        cat.sets = values.groupby(by=cat.key)[\"ISO\"].agg(sorted)\n",
    "    elif isinstance(cat, MultiNominalCategory):\n",
    "        cat.sets = values.explode(column=cat.key).groupby(by=cat.key)[\"ISO\"].agg(sorted)\n",
    "\n",
    "while True:\n",
    "    # Retain only sets with at least 3 (FIELD_SIZE) elements\n",
    "    num_sets_0 = sum(len(cat.sets) for cat in nominal_categories.values())\n",
    "    for cat in nominal_categories.values():\n",
    "        cat.sets = cat.sets[cat.sets.apply(len) >= FIELD_SIZE]\n",
    "    num_sets_1 = sum(len(cat.sets) for cat in nominal_categories.values())\n",
    "    if num_sets_0 != num_sets_1:\n",
    "        print(f\"Removed {num_sets_0 - num_sets_1} category sets\")\n",
    "    # Retain only countries contained in sets of at least 2 different categories (-> has matching row+column)\n",
    "    category_contents = {cat.key: cat.sets.sum() for cat in nominal_categories.values()}\n",
    "    # {cat: len(cc) for cat, cc in category_contents.items()}\n",
    "    contents = set().union(*[set(cc) for cc in category_contents.values()])\n",
    "    print(\"contents:\", len(contents))\n",
    "    retain = {c for c in contents if len([key for key, cc in category_contents.items() if c in cc]) >= 2}\n",
    "    print(\"retain:\", len(retain))\n",
    "    remove = contents.difference(retain)\n",
    "    \n",
    "    for cat in nominal_categories.values():\n",
    "        cat.sets = cat.sets.apply(lambda cc: [c for c in cc if c in retain])\n",
    "    if not remove:\n",
    "        break\n",
    "    print(f\"Removed {len(remove)} countries:\", remove)\n",
    "    print(\"Repeat ...\")\n",
    "\n",
    "list(nominal_categories.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_categories[\"starting_letter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sets(set1, set2):\n",
    "    if len(set1) < len(set2):\n",
    "        return -1\n",
    "    if len(set1) > len(set2):\n",
    "        return 1\n",
    "    l1 = list(sorted(set(set1)))\n",
    "    l2 = list(sorted(set(set2)))\n",
    "    if l1 < l2:\n",
    "        return -1\n",
    "    if l1 > l2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def min_set(set1, set2):\n",
    "    cmp = compare_sets(set1, set2)\n",
    "    return set2 if cmp > 0 else set1\n",
    "\n",
    "def max_set(set1, set2):\n",
    "    cmp = compare_sets(set1, set2)\n",
    "    return set2 if cmp < 0 else set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = (\"flag_colors\", \"Red\")\n",
    "col = (\"flag_colors\", \"White\")\n",
    "\n",
    "print(min_set(row, col), max_set(row, col))\n",
    "print(set(nominal_categories[row[0]].sets[row[1]]).intersection(nominal_categories[col[0]].sets[col[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "setkeys = sum([[(cat.key, value) for value in cat.sets.index] for cat in nominal_categories.values()], [])\n",
    "\n",
    "print(\"Number of values per category:\")\n",
    "print({cat.key: len(cat.sets) for cat in nominal_categories.values()})\n",
    "\n",
    "cells = {(min_set(row, col), max_set(row, col)): set(nominal_categories[row[0]].sets[row[1]]).intersection(nominal_categories[col[0]].sets[col[1]])\n",
    "         for row, col in itertools.combinations(setkeys, 2) if row[0] != col[0] or (row[1] != col[1] and isinstance(nominal_categories[row[0]], MultiNominalCategory))}\n",
    "\n",
    "print(f\"Generated {len(cells)} cells\")\n",
    "\n",
    "# Bring cells to DataFrame to do filtering (cell size etc.)\n",
    "cell_info = pd.DataFrame([{\"row_cat\": row[0], \"row_val\": row[1], \"col_cat\": col[0], \"col_val\": col[1], \"contents\": contents} for (row, col), contents in cells.items()])\n",
    "cell_info[\"size\"] = cell_info[\"contents\"].apply(len)\n",
    "\n",
    "# display(cell_info[cell_info[\"row_cat\"] == cell_info[\"col_cat\"]])\n",
    "\n",
    "# cell_info[\"size\"].value_counts()\n",
    "cell_info = cell_info[(cell_info[\"size\"] >= MIN_CELL_SIZE) & (cell_info[\"size\"] <= MAX_CELL_SIZE)]\n",
    "plt.hist(cell_info[\"size\"], rwidth=.9, bins=[x-.5 for x in range(cell_info[\"size\"].min(), cell_info[\"size\"].max() + 1)])\n",
    "plt.title(\"Districution of cell sizes\")\n",
    "\n",
    "# Bring back to dict with tuple access\n",
    "cell_keys = cell_info.apply(lambda row: ((row[\"row_cat\"], row[\"row_val\"]), (row[\"col_cat\"], row[\"col_val\"])), axis=1)\n",
    "cells = {key: contents for key, contents in zip(cell_keys, cell_info[\"contents\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(row, col) for row, col in cells.keys() if row[0] == col[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(setkeys)\n",
    "G.add_edges_from(cells.keys())\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find 2 distinct node sets of size FIELD_SIZE that are mutually completely connected\n",
    "# (connections within the set also allowed, that's why it is not necessarily a complete bipartite subgraph)\n",
    "\n",
    "def subsets_of_sizes(S, sizes):\n",
    "    return itertools.chain(*[itertools.combinations(S, k) for k in sizes])\n",
    "\n",
    "def row_col_assignments(categories):\n",
    "    categories = set(categories.values())\n",
    "    # TODO incorporate number of category values into iterations\n",
    "\n",
    "    possible_numbers_of_distinct_row_cats = range(1, min(len(categories) // 2, FIELD_SIZE) + 1)\n",
    "    # // 2 assuming there are at least as many distinct categories in the columns\n",
    "    for row_cats in subsets_of_sizes(categories, possible_numbers_of_distinct_row_cats):\n",
    "        row_cats = set(row_cats)\n",
    "        possible_col_cats = categories.difference([cat for cat in row_cats if not isinstance(cat, MultiNominalCategory)])\n",
    "        possible_numbers_of_distinct_col_cats = range(len(row_cats), min(len(possible_col_cats), FIELD_SIZE) + 1)\n",
    "        for col_cats in subsets_of_sizes(possible_col_cats, possible_numbers_of_distinct_col_cats):\n",
    "            col_cats = set(col_cats)\n",
    "            if len(row_cats) == len(col_cats):\n",
    "                # When equal size: Assume row_cats < col_cats (with lexicographical order)\n",
    "                if compare_sets(row_cats, col_cats) == 1:\n",
    "                    continue\n",
    "            # Sampled too many?\n",
    "            only_rows = len(row_cats.difference(col_cats))\n",
    "            only_cols = len(col_cats.difference(row_cats))\n",
    "            both = len(row_cats.intersection(col_cats))\n",
    "            if only_rows + only_cols + both > 2 * FIELD_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # Only allow for up to 2 appearances of a category in rows/columns.\n",
    "            # When having a multi-category in row&column, only allow for one appearance each.\n",
    "            if 2 * only_rows + both < FIELD_SIZE or 2 * only_cols + both < FIELD_SIZE:\n",
    "                continue\n",
    "            \n",
    "            yield (row_cats, col_cats)\n",
    "\n",
    "row_col_cats = list(row_col_assignments(nominal_categories))\n",
    "print(f\"Generated {len(row_col_cats)} row-column category assignments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(rows, cols) for rows, cols in row_col_cats if rows.intersection(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([(len(rows), len(cols)) for rows, cols in row_col_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_col_info = pd.DataFrame([{\"rows\": rows, \"cols\": cols, \"difficulty\": sum([cat.difficulty for cat in rows.union(cols)])} for rows, cols in row_col_cats])\n",
    "# row_col_info.sort_values(by=\"difficulty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(row_col_info[\"difficulty\"], rwidth=.9)\n",
    "plt.title(\"Difficulty of generated row-column assignments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_label(cat: Category, value):\n",
    "    if cat.key == \"continent\":\n",
    "        continents = {\"AF\": \"Africa\", \"EU\": \"Europe\", \"AS\": \"Asia\", \"NA\": \"N. America\", \"SA\": \"S. America\", \"OC\": \"Oceania\"}\n",
    "        return continents[value]\n",
    "    return f\"{cat.name}: {value}\"\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, values, cells, rows, cols):\n",
    "        self.size = FIELD_SIZE\n",
    "        self.values = values  # All possible values to be guessed (list of dicts)\n",
    "        self.cells = cells  # 3x3 array containing list of possible solutions\n",
    "        self.rows = rows  # rows (tuples of form (Category, value))\n",
    "        self.cols = cols  # columns (as above)\n",
    "    \n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"size\": self.size,\n",
    "            \"values\": self.values,\n",
    "            \"cells\": [[list(cell) for cell in row] for row in self.cells],\n",
    "            \"labels\": {\n",
    "                \"rows\": [get_label(cat, value) for cat, value in self.rows],\n",
    "                \"cols\": [get_label(cat, value) for cat, value in self.cols]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def to_dataframe(self, solution=False):\n",
    "        game_df = pd.DataFrame(data=self.cells if solution else None,\n",
    "                               index=[get_label(cat, value) for cat, value in self.rows],\n",
    "                               columns=[get_label(cat, value) for cat, value in self.cols])\n",
    "        game_df.fillna(\"\", inplace=True)\n",
    "        return game_df\n",
    "\n",
    "\n",
    "def get_cell(cells, row, col):\n",
    "    if (row, col) in cells:\n",
    "        return cells[(row, col)]\n",
    "    if (col, row) in cells:\n",
    "        return cells[(col, row)]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample possible game setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_values = values[[\"ISO\", \"Country\"]]\n",
    "country_values.columns = [\"iso\", \"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def get_allowed_sets(cross_sets, parallel_sets):\n",
    "    # Not 2 identical (cat, value) sets in the game\n",
    "    choice = set(setkeys).difference(cross_sets).difference(parallel_sets)\n",
    "    # Not 2 crossing identical categories, except MultiNominal, but then only 1 each\n",
    "    # Each category only allowed twice\n",
    "    cross_cats = Counter(cat for cat, value in cross_sets)\n",
    "    parallel_cats = Counter(cat for cat, value in parallel_sets)\n",
    "    choice = {(cat, value) for cat, value in choice\n",
    "              if (cat not in cross_cats and parallel_cats.get(cat, 0) <= 1)\n",
    "              or (isinstance(nominal_categories[cat], MultiNominalCategory) and cross_cats[cat] == 1 and cat not in parallel_cats)}\n",
    "    \n",
    "    return choice\n",
    "\n",
    "\n",
    "def sample_fitting_set(cross_sets, parallel_sets):\n",
    "    \"\"\" Samples a new column assuming cross_sets are the rows and parallel_sets the previous columns. \"\"\"\n",
    "    choice = list(get_allowed_sets(cross_sets, parallel_sets))\n",
    "    random.shuffle(choice)\n",
    "    for c in choice:\n",
    "        if all(get_cell(cells, c, crossing) for crossing in cross_sets):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def sample_game():\n",
    "    MAX_TRIES = 100\n",
    "    for i in range(MAX_TRIES):\n",
    "        row0, col0 = random.choice(list(cells.keys()))\n",
    "        rows, cols = [row0], [col0]\n",
    "        for _ in range(FIELD_SIZE - 1):\n",
    "            new_col = sample_fitting_set(cross_sets=rows, parallel_sets=cols)\n",
    "            if new_col is not None:\n",
    "                cols.append(new_col)\n",
    "            else:\n",
    "                break\n",
    "            new_row = sample_fitting_set(cross_sets=cols, parallel_sets=rows)\n",
    "            if new_row is not None:\n",
    "                rows.append(new_row)\n",
    "            else:\n",
    "                break\n",
    "        if len(rows) == FIELD_SIZE and len(cols) == FIELD_SIZE:\n",
    "#             print(f\"Successfully created game after {i+1} iterations.\")\n",
    "            break\n",
    "\n",
    "    if random.random() > .5:\n",
    "        rows, cols = cols, rows\n",
    "    \n",
    "    game = Game(values=country_values.to_dict(orient=\"records\"),\n",
    "                cells=[[get_cell(cells, row, col) for col in cols] for row in rows],\n",
    "                rows=[(nominal_categories[cat], value) for cat, value in rows],\n",
    "                cols=[(nominal_categories[cat], value) for cat, value in cols])\n",
    "    return game\n",
    "\n",
    "# games = [sample_game() for _ in range(1000)]\n",
    "# game = sample_game()\n",
    "# game.to_json()\n",
    "# game.to_dataframe(solution=True)\n",
    "\n",
    "# get_allowed_sets([('capital_ending_letter', 'T'), ('flag_colors', 'Red'), ('starting_letter', 'T')], [('capital_starting_letter', 'O')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = [sample_game() for _ in range(1000)]\n",
    "\n",
    "json.dump([game.to_json() for game in games], open(\"games.json\", mode=\"w\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # NUM_CAT_ORIENTATIONS = 10  # assignments of categories to being row or column\n",
    "# # NUM_SETUPS_PER_ORIENTATION = 1  # how many fields to generate per orientation\n",
    "# NUM_GAMES = 10\n",
    "\n",
    "# setups = []\n",
    "\n",
    "# setkeys_by_cat = {cat: [(cat, value) for cat1, value in setkeys if cat == cat1] for cat in nominal_categories.keys()}\n",
    "\n",
    "# def sample_setup(row_col_cats):\n",
    "#     while True:\n",
    "#         row_cats, col_cats = random.choice(row_col_cats)\n",
    "#         if random.random() < .5:\n",
    "#             row_cats, col_cats = col_cats, row_cats\n",
    "\n",
    "#     #     print(row_cats, col_cats)\n",
    "\n",
    "#         # Multi-value category is allowed in 1 row and 1 column at once, but not more than that\n",
    "#         multi_cats = row_cats.intersection(col_cats)\n",
    "#         # Check self-intersection of multi-value category\n",
    "#         multi_setkeys = set().union(*[setkeys_by_cat[cat.key] for cat in multi_cats])\n",
    "\n",
    "#         row_setkeys = set().union(*[setkeys_by_cat[cat.key] for cat in row_cats])\n",
    "#         col_setkeys = set().union(*[setkeys_by_cat[cat.key] for cat in col_cats])\n",
    "\n",
    "#         # Cell subgraph with the selected categories (all values)\n",
    "#         G1 = nx.subgraph(G, row_setkeys.union(col_setkeys)).copy()\n",
    "#     #     G1 = nx.subgraph(G, [(cat, value) for cat, value in setkeys if cat in row_cats or cat in col_cats]).copy()\n",
    "\n",
    "#         # Make \"anti-bipartite\" (make subgraph of row resp. col categories complete)\n",
    "#         # (Except for mult-categories appearing in both rows and cols)\n",
    "#         # (The anti-bipartite property can only be ensured if the same multi-category only appears in ONE row and column)\n",
    "#         if not multi_cats:\n",
    "#             G1.add_edges_from(itertools.combinations(row_setkeys.difference(multi_setkeys), 2))\n",
    "#             G1.add_edges_from(itertools.combinations(col_setkeys.difference(multi_setkeys), 2))\n",
    "#         else:\n",
    "#             # TODO add these edges only if the cell exists! (and this should already have happened)\n",
    "#     #         G1.add_edges_from(itertools.product(row_setkeys.difference(multi_setkeys), multi_setkeys))\n",
    "#     #         G1.add_edges_from(itertools.product(col_setkeys.difference(multi_setkeys), multi_setkeys))\n",
    "#     #         G1.add_edges_from(((cat1, value1), (cat2, value2))\n",
    "#     #                           for (cat1, value1), (cat2, value2)\n",
    "#     #                           in itertools.combinations(multi_setkeys, 2)\n",
    "#     #                           if cat1 != cat2)\n",
    "#             # TODO have to assign multi-cat values (setkeys) to being row/col\n",
    "#             # Idea: first sample clique treating the multi-cat as row only / col only.\n",
    "#             # Then merge both results and extract possible row-col assignments of the multi setkeys.\n",
    "#             # Then do another final clique check.\n",
    "#             G1r = G1.copy()\n",
    "#             G1r.add_edges_from(itertools.combinations(row_setkeys, 2))\n",
    "#             G1r.add_edges_from(itertools.combinations(col_setkeys.difference(multi_setkeys), 2))\n",
    "#             G1c = G1.copy()\n",
    "#             G1c.add_edges_from(itertools.combinations(row_setkeys.difference(multi_setkeys), 2))\n",
    "#             G1c.add_edges_from(itertools.combinations(col_setkeys, 2))\n",
    "#             cliques_r = [clique for clique in nx.find_cliques(G1r) if len(clique) >= 2 * FIELD_SIZE - len(multi_cats) and len(set(cat for cat, _ in clique)) > 1]\n",
    "#             cliques_c = [clique for clique in nx.find_cliques(G1c) if len(clique) >= 2 * FIELD_SIZE - len(multi_cats) and len(set(cat for cat, _ in clique)) > 1]\n",
    "        \n",
    "#             # merge: intersection of non-multi, union of multi setkeys.\n",
    "# #             clique_pairs = [(clr, clc) for clr, clc in itertools.product(cliques_r, cliques_c)\n",
    "# #                             if set(clr).difference(multi_setkeys) == set(clc).difference(multi_setkeys)\n",
    "# #                             and set(clr).intersection(multi_setkeys).isdisjoint(set(clc).intersection(multi_setkeys))]\n",
    "#             for clr, clc in itertools.product(cliques_r, cliques_c):\n",
    "#         # tTODO bää\n",
    "#                 both = set(clr).intersection(clc)\n",
    "#                 multi_r = set(clr).intersection(multi_setkeys)\n",
    "#                 multi_c = set(clc).intersection(multi_setkeys)\n",
    "#                 single_r = both.intersection(row_setkeys).difference(multi_c)\n",
    "#                 single_c = both.intersection(col_setkeys).difference(multi_r)\n",
    "#                 if len(both_r)\n",
    "                \n",
    "#                 row_setkeys = set((cat, value) for cat, value in both if nominal_categories[cat] in row_cats)\n",
    "#                 col_setkeys = set((cat, value) for cat, value in both if nominal_categories[cat] in col_cats)\n",
    "    \n",
    "#             return None\n",
    "\n",
    "#         # Compute cliques\n",
    "#         cliques = [clique for clique in nx.find_cliques(G1) if len(clique) >= 2 * FIELD_SIZE and len(set(cat for cat, _ in clique)) > 1]\n",
    "#         del G1\n",
    "#         random.shuffle(cliques)\n",
    "#         for i, clique in enumerate(cliques):\n",
    "#             row_setkeys = set((cat, value) for cat, value in clique if nominal_categories[cat] in row_cats)\n",
    "#             col_setkeys = set((cat, value) for cat, value in clique if nominal_categories[cat] in col_cats)\n",
    "# #             col_setkeys = set(clique).difference(row_setkeys)\n",
    "\n",
    "#             # Is clique large enough?\n",
    "#             if len(row_setkeys) < FIELD_SIZE or len(col_setkeys) < FIELD_SIZE:\n",
    "#                 continue\n",
    "\n",
    "#     #         print(f\"#{i}, size {len(row_setkeys)}x{len(col_setkeys)}\")#, \"rows:\", row_setkeys, \"cols:\", col_setkeys)\n",
    "#             #set((cat, value) for cat, value in clique if cat in col_cats)\n",
    "\n",
    "#             # visualize complete bipartite graph\n",
    "#     #         G2 = nx.Graph()\n",
    "#     #         G2.add_nodes_from(row_setkeys, bipartite=0)\n",
    "#     #         G2.add_nodes_from(col_setkeys, bipartite=1)\n",
    "#     #         G2.add_edges_from([(u, v) for u, v in cells.keys() if u in row_setkeys and v in col_setkeys])\n",
    "#     #         nx.draw(G2)\n",
    "#     #         plt.show()\n",
    "#     #         del G2\n",
    "        \n",
    "#             rows = random.sample(row_setkeys, FIELD_SIZE)\n",
    "#             cols = random.sample(col_setkeys, FIELD_SIZE)\n",
    "#             return rows, cols\n",
    "\n",
    "#         if not cliques:\n",
    "#             print(\"Found no cliques for category setup\", (row_cats, col_cats))\n",
    "#         del cliques\n",
    "        \n",
    "# # for rows, cols in setups:\n",
    "# #     print(rows, cols)\n",
    "\n",
    "# setups = []\n",
    "# while len(setups) < NUM_GAMES:\n",
    "#     setups.append(sample_setup(row_col_cats))\n",
    "\n",
    "# games = [Game(values=values[\"Country\"].tolist(),\n",
    "#               cells=[[get_cell(cells, row, col) for col in cols] for row in rows],\n",
    "#               rows=[(nominal_categories[cat], value) for cat, value in rows],\n",
    "#               cols=[(nominal_categories[cat], value) for cat, value in cols]) for rows, cols in setups]\n",
    "\n",
    "# for game in games:\n",
    "#     display(game.to_dataframe(solution=True))\n",
    "# #     print(list(G1.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# NUM_CAT_ORIENTATIONS = 10  # assignments of categories to being row or column\n",
    "# NUM_SETUPS_PER_ORIENTATION = 1  # how many fields to generate per orientation\n",
    "\n",
    "# setups = []\n",
    "\n",
    "# setkeys_by_cat = {cat: [(cat, value) for cat1, value in setkeys if cat == cat1] for cat in nominal_categories.keys()}\n",
    "\n",
    "# for row_cats, col_cats in random.sample(row_col_cats, NUM_CAT_ORIENTATIONS):\n",
    "#     if random.random() < .5:\n",
    "#         row_cats, col_cats = col_cats, row_cats\n",
    "    \n",
    "# #     print(row_cats, col_cats)\n",
    "    \n",
    "#     # Multi-value category is allowed in 1 row and 1 column at once, but not more than that\n",
    "#     multi_cats = row_cats.intersection(col_cats)\n",
    "#     # Check self-intersection of multi-value category\n",
    "#     multi_setkeys = set().union(*[setkeys_by_cat[cat] for cat in multi_cats])\n",
    "    \n",
    "#     row_setkeys = set().union(*[setkeys_by_cat[cat] for cat in row_cats])\n",
    "#     col_setkeys = set().union(*[setkeys_by_cat[cat] for cat in col_cats])\n",
    "    \n",
    "#     # Cell subgraph with the selected categories (all values)\n",
    "#     G1 = nx.subgraph(G, row_setkeys.union(col_setkeys)).copy()\n",
    "# #     G1 = nx.subgraph(G, [(cat, value) for cat, value in setkeys if cat in row_cats or cat in col_cats]).copy()\n",
    "    \n",
    "#     # Make \"anti-bipartite\" (make subgraph of row resp. col categories complete)\n",
    "#     # (Except for mult-categories appearing in both rows and cols)\n",
    "#     # (The anti-bipartite property can only be ensured if the same multi-category only appears in ONE row and column)\n",
    "#     G1.add_edges_from(itertools.combinations(row_setkeys.difference(multi_setkeys), 2))\n",
    "#     G1.add_edges_from(itertools.combinations(col_setkeys.difference(multi_setkeys), 2))\n",
    "#     G1.add_edges_from(itertools.product(row_setkeys, multi_setkeys))\n",
    "#     G1.add_edges_from(itertools.product(col_setkeys, multi_setkeys))\n",
    "#     G1.add_edges_from(((cat1, value1), (cat2, value2))\n",
    "#                       for (cat1, value1), (cat2, value2)\n",
    "#                       in itertools.combinations(multi_setkeys, 2)\n",
    "#                       if cat1 != cat2)\n",
    "#     # Compute cliques\n",
    "#     cliques = [clique for clique in nx.find_cliques(G1) if len(clique) >= 2 * FIELD_SIZE and len(set(cat for cat, _ in clique)) > 1]\n",
    "#     del G1\n",
    "#     random.shuffle(cliques)\n",
    "#     bipartite_cliques = []\n",
    "#     for i, clique in enumerate(cliques):\n",
    "#         row_setkeys = set((cat, value) for cat, value in clique if cat in row_cats)\n",
    "#         col_setkeys = set(clique).difference(row_setkeys)\n",
    "        \n",
    "#         if len(row_setkeys) < FIELD_SIZE or len(col_setkeys) < FIELD_SIZE:\n",
    "#             continue\n",
    "        \n",
    "# #         print(f\"#{i}, size {len(row_setkeys)}x{len(col_setkeys)}\")#, \"rows:\", row_setkeys, \"cols:\", col_setkeys)\n",
    "#         #set((cat, value) for cat, value in clique if cat in col_cats)\n",
    "#         bipartite_cliques.append((row_setkeys, col_setkeys))\n",
    "        \n",
    "#         # visualize complete bipartite graph\n",
    "# #         G2 = nx.Graph()\n",
    "# #         G2.add_nodes_from(row_setkeys, bipartite=0)\n",
    "# #         G2.add_nodes_from(col_setkeys, bipartite=1)\n",
    "# #         G2.add_edges_from([(u, v) for u, v in cells.keys() if u in row_setkeys and v in col_setkeys])\n",
    "# #         nx.draw(G2)\n",
    "# #         plt.show()\n",
    "# #         del G2\n",
    "        \n",
    "#         if len(bipartite_cliques) >= NUM_SETUPS_PER_ORIENTATION and NUM_SETUPS_PER_ORIENTATION is not None:\n",
    "#             break\n",
    "            \n",
    "#     for row_setkeys, col_setkeys in bipartite_cliques:\n",
    "#         rows = random.sample(row_setkeys, FIELD_SIZE)\n",
    "#         cols = random.sample(col_setkeys, FIELD_SIZE)\n",
    "#         setups.append((rows, cols))\n",
    "    \n",
    "#     if not cliques:\n",
    "#         print(\"Found no cliques for category setup\", (row_cats, col_cats))\n",
    "#     del cliques\n",
    "        \n",
    "# # for rows, cols in setups:\n",
    "# #     print(rows, cols)\n",
    "\n",
    "\n",
    "# games = [Game(values=values[\"Country\"].tolist(),\n",
    "#               cells=[[get_cell(cells, row, col) for col in cols] for row in rows],\n",
    "#               rows=[(nominal_categories[cat], value) for cat, value in rows],\n",
    "#               cols=[(nominal_categories[cat], value) for cat, value in cols]) for rows, cols in setups]\n",
    "\n",
    "# for game in games:\n",
    "#     display(game.to_dataframe())\n",
    "# #     print(list(G1.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible combinations of categories along the rows/columns (FIELD_SIZE)\n",
    "# Can use same category multiple times, but not in both a row and a column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"neighbours\"].apply(lambda x: not x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Ideas\n",
    "\n",
    "- Starting/ending with letter\n",
    "- Capital starting/ending with letter\n",
    "- Top/Bottom 20 (area/population)\n",
    "- (dynamic): Bigger/smaller/More/less populated than X\n",
    "- Island?\n",
    "- Landlocked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal_categories = {\n",
    "#     \"Continent\": df[\"Continent\"],\n",
    "#     \"Starting letter\": df[\"Country\"].apply(lambda x: x[0].upper()),\n",
    "#     \"Ending letter\": df[\"Country\"].apply(lambda x: x[-1].upper()),\n",
    "#     \"Capital starting letter\": df[\"Capital\"].apply(lambda x: x[0].upper()),\n",
    "#     \"Capital ending letter\": df[\"Capital\"].apply(lambda x: x[-1].upper()),\n",
    "# }\n",
    "# bool_categories = {\n",
    "#     \"Island\": df[\"neighbours\"].apply(lambda x: not x),\n",
    "#     \"Landlocked\": None,\n",
    "#     \"Top 20 Area\": df.ISO.isin(df.nlargest(10, 'Area(in sq km)').ISO),\n",
    "#     \"Bottom 20 Area\": df.ISO.isin(df.nsmallest(10, 'Area(in sq km)').ISO),\n",
    "#     \"Top 20 Pop.\": df.ISO.isin(df.nlargest(10, 'Population').ISO),\n",
    "#     \"Bottom 20 Pop.\": df.ISO.isin(df.nsmallest(10, 'Population').ISO),\n",
    "# }\n",
    "# values = pd.concat([df[[\"ISO\", \"Country\"]], pd.DataFrame(nominal_categories), pd.DataFrame(bool_categories)], axis=1)\n",
    "# values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
