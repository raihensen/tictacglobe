{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Ambiguous continents:\n",
    "  - Timor-Leste (OC, AS)\n",
    "  - Armenia, Azerbaijan, Georgia (EU, AS)\n",
    "  - Trinidad and Tobago (NA, SA)\n",
    "\n",
    "Adding ambiguous continents should not create new cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD_SIZE = 3\n",
    "MIN_CELL_SIZE = 1\n",
    "MAX_CELL_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = json.load(open(\"local/countries_processed.json\", encoding=\"utf-8\"))\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter & rename columns\n",
    "df.columns = ['iso', 'iso3', 'iso_numeric', 'fips', 'name', 'capital',\n",
    "              'area_km2', 'population', 'continent', 'tld',\n",
    "              'currency_code', 'currency_name', 'phone', 'zip_format', 'zip_regex',\n",
    "              'languages', 'geonameid', 'neighbors', 'eq_fips', 'parent', 'territories', 'neighbors_t']\n",
    "subset = ['iso', 'name', 'capital', 'continent',\n",
    "          'area_km2', 'population',\n",
    "          'currency_code', 'currency_name', 'languages',\n",
    "          'territories', 'neighbors_t']\n",
    "df = df[subset]\n",
    "df.rename(columns={\"neighbors_t\": \"neighbors\"}, inplace=True)\n",
    "\n",
    "# Additional columns & global fixes\n",
    "df[\"continent\"].fillna(\"NA\", inplace=True)  # North America fix\n",
    "df[\"landlocked\"] = df[\"iso\"].isin(\"AF,AD,AM,AT,AZ,BY,BT,BO,BW,BF,BI,CF,TD,CZ,SZ,ET,HU,KZ,XK,LA,LS,LI,LU,MW,ML,MD,MN,NP,NE,MK,PY,RW,SM,RS,SK,SS,CH,TJ,UG,VA,ZA,ZW\".split(\",\"))\n",
    "df[\"island\"] = df[\"neighbors\"].apply(len) == 0\n",
    "\n",
    "def add_alternative_value(df, col, country, *values):\n",
    "    cols = list(df.columns)\n",
    "    if col not in cols:\n",
    "        return False\n",
    "    \n",
    "    # Add alternative column if not exists\n",
    "    altcol = col + \"_alt\"\n",
    "    if altcol not in cols:\n",
    "        df.insert(cols.index(col) + 1, altcol, df[col].apply(lambda x: []))\n",
    "    \n",
    "    # Find country\n",
    "    if country in df[\"name\"].values:\n",
    "        index = df.index[df[\"name\"] == country][0]\n",
    "    elif country in df[\"iso\"].values:\n",
    "        index = df.index[df[\"iso\"] == country][0]\n",
    "    else:\n",
    "        print(f\"country {country} not found!\")\n",
    "        return False\n",
    "    \n",
    "    # Add values\n",
    "    values = sum([[x] if not isinstance(x, list) else x for x in values], [])\n",
    "#     values = [val for val in values if val not in df.loc[index, altcol]]\n",
    "    \n",
    "    # Warn if value to-be-added is the actual value. Swap if not first-named\n",
    "    if df.loc[index, col] in values:\n",
    "        if values[0] == df.loc[index, col]:\n",
    "            print(f\"{country}/{col}: '{df.loc[index, col]}' is already set as main value - skipping\")\n",
    "        else:\n",
    "            print(f\"{country}/{col}: '{df.loc[index, col]}' is already set as main value - swapping with '{values[0]}'\")\n",
    "            df.loc[index, col] = values[0]\n",
    "        values = values[1:]\n",
    "\n",
    "    for val in values:\n",
    "        if val not in df.loc[index, altcol]:\n",
    "            df.loc[index, altcol].append(val)\n",
    "    return True\n",
    "\n",
    "# Individual fixes\n",
    "df.loc[df[\"name\"] == \"Palau\", \"capital\"] = \"Ngerulmud\"\n",
    "df.loc[df[\"iso\"] == \"PS\", \"name\"] = \"Palestine\"\n",
    "\n",
    "# Alternative values\n",
    "# Names\n",
    "add_alternative_value(df, \"name\", \"CI\", \"Ivory Coast\", \"Côte d'Ivoire\")\n",
    "add_alternative_value(df, \"name\", \"TR\", \"Türkiye\", \"Turkey\")\n",
    "add_alternative_value(df, \"name\", \"VA\", \"Vatican\", \"Vatican City\")\n",
    "\n",
    "# Multiple continents (source: https://en.wikipedia.org/wiki/List_of_transcontinental_countries)\n",
    "add_alternative_value(df, \"continent\", \"Armenia\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Georgia\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Azerbaijan\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Trinidad and Tobago\", \"SA\", \"NA\")\n",
    "add_alternative_value(df, \"continent\", \"Panama\", \"NA\", \"SA\")\n",
    "add_alternative_value(df, \"continent\", \"Egypt\", \"AF\", \"AS\")\n",
    "add_alternative_value(df, \"continent\", \"Russia\", \"EU\", \"AS\")\n",
    "add_alternative_value(df, \"continent\", \"TR\", \"AS\", \"EU\")\n",
    "add_alternative_value(df, \"continent\", \"Timor Leste\", \"AS\", \"OC\")\n",
    "\n",
    "# Multiple/unclear capital (source: https://en.wikipedia.org/wiki/List_of_countries_with_multiple_capitals)\n",
    "add_alternative_value(df, \"capital\", \"Kazakhstan\", \"Astana\", \"Nur-Sultan\")\n",
    "add_alternative_value(df, \"capital\", \"Bolivia\", \"La Paz\", \"Sucre\")\n",
    "add_alternative_value(df, \"capital\", \"Burundi\", \"Gitega\", \"Bujumbura\")\n",
    "add_alternative_value(df, \"capital\", \"CI\", \"Yamoussoukro\", \"Abidjan\")\n",
    "add_alternative_value(df, \"capital\", \"Eswatini\", \"Mbabane\", \"Lobamba\")\n",
    "add_alternative_value(df, \"capital\", \"Malaysia\", \"Kuala Lumpur\", \"Putrajaya\")\n",
    "add_alternative_value(df, \"capital\", \"Netherlands\", \"Amsterdam\", \"The Hague\")\n",
    "add_alternative_value(df, \"capital\", \"Palestine\", \"Ramallah\", \"Jerusalem\", \"East Jerusalem\")\n",
    "add_alternative_value(df, \"capital\", \"South Africa\", \"Pretoria\", \"Cape Town\", \"Bloemfontein\")\n",
    "add_alternative_value(df, \"capital\", \"Sri Lanka\", \"Colombo\", \"Sri Jayawardenepura Kotte\")\n",
    "\n",
    "# Capitals with multiple spellings / alternative names\n",
    "add_alternative_value(df, \"capital\", \"US\", \"Washington\", \"Washington, DC\")\n",
    "\n",
    "\n",
    "# Display all changes\n",
    "altcols = [col for col in df.columns if col.endswith(\"_alt\")]\n",
    "print(\"\\nAll countries with alternative values:\")\n",
    "df[df[altcols].applymap(len).sum(axis=1) > 0]\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"iso\"] == \"PS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import flag colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign colors\n",
    "colors = pd.read_csv(\"local/flag-colors.csv\", sep=\";\")\n",
    "colors.columns = [\"country\", \"color\"]\n",
    "colors[\"country\"].fillna(method='ffill', inplace=True)\n",
    "colors.dropna(inplace=True)\n",
    "colors = colors.applymap(lambda x: x.strip())\n",
    "\n",
    "\n",
    "cmap = {\n",
    "    \"Light Blue\": \"Blue\",\n",
    "    \"Dark Blue\": \"Blue\",\n",
    "    \"Sky Blue\": \"Blue\",\n",
    "    \"Aquamarine Blue\": \"Blue\",\n",
    "    \"Fulvous\": \"Orange\",\n",
    "    \"Crimson\": \"Red\",\n",
    "    \"Saffron Orange\": \"Orange\",\n",
    "    \"Green Or Blue\": \"Green\",\n",
    "    \"Maroon\": \"Red\",  # Qatar, Sri Lanka,\n",
    "    \"Olive Green\": \"Green\",\n",
    "    \"Yellow\": \"Yellow/Gold\",\n",
    "    \"Gold\": \"Yellow/Gold\",\n",
    "    \"Golden\": \"Yellow/Gold\",\n",
    "}\n",
    "name_map = {\n",
    "    'American Samoa': None,\n",
    "    'Anguilla': None,\n",
    "    'Antigua And Barbuda': 'Antigua and Barbuda',\n",
    "    'Aruba': None,\n",
    "    'Bermuda': None,\n",
    "    'Bosnia And Herzegovina': 'Bosnia and Herzegovina',\n",
    "    'Bouvet Island': None,\n",
    "    'Brunei Darussalam': \"Brunei\",\n",
    "    'Cook Islands': None,\n",
    "    'Curaçao': None,\n",
    "    \"Côte D'Ivoire\": 'Ivory Coast',\n",
    "    'Democratic Republic Of The Congo': 'Democratic Republic of the Congo',\n",
    "    'French Polynesia': None,\n",
    "    'Holy See (Vatican City State)': \"Vatican\",\n",
    "    'Niue': None,\n",
    "    'Norfolk Island': None,\n",
    "#     'Palestine': 'Palestinian Territory',\n",
    "    'Pitcairn Islands': None,\n",
    "    'Republic Of The Congo': 'Republic of the Congo',\n",
    "    'Russian Federation': \"Russia\",\n",
    "    'Saint Kitts And Nevis': 'Saint Kitts and Nevis',\n",
    "    'Saint Vincent And The Grenadines': 'Saint Vincent and the Grenadines',\n",
    "    'Sao Tome And Principe': 'Sao Tome and Principe',\n",
    "    'Syrian Arab Republic': \"Syria\",\n",
    "    'Tanzania, United Republic Of': \"Tanzania\",\n",
    "    'Trinidad And Tobago': 'Trinidad and Tobago',\n",
    "    'Åland Islands': None,\n",
    "    'Turkey': 'Türkiye'\n",
    "}\n",
    "add = [\n",
    "    {\"country\": \"Timor Leste\", \"color\": [\"Red\", \"Yellow/Gold\", \"Black\", \"White\"]},\n",
    "    {\"country\": \"Kosovo\", \"color\": [\"Blue\", \"Yellow/Gold\", \"White\"]},\n",
    "    {\"country\": \"Taiwan\", \"color\": [\"Red\", \"Blue\", \"White\"]}\n",
    "]\n",
    "\n",
    "colors[\"color\"] = colors[\"color\"].apply(lambda c: cmap.get(c, c))\n",
    "colors[\"country\"] = colors[\"country\"].apply(lambda x: name_map.get(x, x))\n",
    "colors1 = colors.groupby(by=\"country\")[\"color\"].agg(list).reset_index()\n",
    "colors1 = colors1.append(add, ignore_index=True)\n",
    "\n",
    "colors2 = pd.merge(df[[\"name\"]], colors1, how=\"left\", left_on=\"name\", right_on=\"country\")\n",
    "colors2_outer = pd.merge(df[[\"name\"]], colors1, how=\"outer\", left_on=\"name\", right_on=\"country\", indicator=True)\n",
    "df[\"flag_colors\"] = colors2[\"color\"]\n",
    "df[\"flag_colors\"] = df[\"flag_colors\"].apply(lambda cc: list(set(cc)))\n",
    "\n",
    "no_flag = df[\"flag_colors\"].isna().sum()\n",
    "print(f\"Assigned colors. {no_flag} countries missing a flag.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply flag color fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cfre = re.compile(r\"^(?:(?:\\[(?P<main_set>[^\\(\\)]*)\\])|(?:(?P<main_add>[^\\(\\)]*)))?(?:,?\\s*\\((?P<optional>[^\\(\\)]*?)\\))?,?\\s*(?:\\(\\((?P<ignore>[^\\(\\)]*?)\\)\\))?$\")\n",
    "\n",
    "def parse_color(c):\n",
    "    cmap = {\"Y/G\": \"Yellow/Gold\", \"R\": \"Red\", \"W\": \"White\", \"B\": \"Blue\", \"Gr\": \"Green\", \"O\": \"Orange\"}\n",
    "    return cmap.get(c, c)\n",
    "    \n",
    "def parse_fixes(specs):\n",
    "    for line in specs:\n",
    "        iso = line[:2]\n",
    "        spec = line[3:]\n",
    "        match = cfre.match(spec)\n",
    "        if match:\n",
    "            for mode, cc in match.groupdict().items():\n",
    "                if cc:\n",
    "                    yield (iso, mode, [parse_color(c.strip()) for c in cc.split(\",\")])\n",
    "        else:\n",
    "            print(spec, \"no match\")\n",
    "\n",
    "color_fixes = open(\"local/flag color fixes.txt\").read().split(\"\\n\")\n",
    "color_fixes = list(parse_fixes(color_fixes))\n",
    "\n",
    "# Apply the fixes\n",
    "for iso, mode, cc in color_fixes:\n",
    "    if iso not in df[\"iso\"].values:\n",
    "        print(f\"Country {iso} not found.\")\n",
    "        continue\n",
    "    index = df.index[df[\"iso\"] == iso][0]\n",
    "    if mode == \"main_set\":\n",
    "        df.at[index, \"flag_colors\"] = cc\n",
    "    elif mode == \"main_add\":\n",
    "        for c in cc:\n",
    "            df.loc[index, \"flag_colors\"].append(c)\n",
    "    elif mode == \"optional\":\n",
    "        add_alternative_value(df, \"flag_colors\", iso, *cc)\n",
    "\n",
    "df[\"flag_colors\"] = df[\"flag_colors\"].apply(lambda cc: list(sorted(set(cc))))\n",
    "if \"flag_colors_alt\" in list(df.columns):\n",
    "    df[\"flag_colors_alt\"] = df[\"flag_colors_alt\"].apply(lambda cc: list(sorted(set(cc))))\n",
    "\n",
    "changes = set(iso for iso, _, _ in color_fixes)    \n",
    "\n",
    "df[df[\"iso\"].isin(changes)][[\"iso\", \"name\", \"flag_colors\", \"flag_colors_alt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # from IPython.display import Image, display\n",
    "# from IPython.display import SVG, display\n",
    "\n",
    "# for row in list(df.iterrows()):\n",
    "#     country = row[1].to_dict()\n",
    "#     print(f'{country[\"name\"]} ({country[\"iso\"]}): {\", \".join(country[\"flag_colors\"])}')\n",
    "#     display(SVG(url=f'https://hatscripts.github.io/circle-flags/flags/{country[\"iso\"].lower()}.svg'))\n",
    "#     print()\n",
    "# # display(Image(filename=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(df[\"flag_colors\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import total_ordering\n",
    "from typing import Callable\n",
    "\n",
    "@total_ordering\n",
    "class Category:\n",
    "    def __init__(self, key: str, name: str, difficulty: float, values: pd.Series, alt_values: pd.Series):\n",
    "        self.key = key\n",
    "        self.alt_key = key + \"_alt\"\n",
    "        self.name = name\n",
    "        self.difficulty = difficulty\n",
    "        self.values = values\n",
    "        self.alt_values = alt_values\n",
    "        self.sets = None\n",
    "        self.alt_sets = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.key < other.key\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.key == other.key\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.key)\n",
    "\n",
    "@total_ordering\n",
    "class NominalCategory(Category):\n",
    "    def __init__(self, df: pd.DataFrame, key: str, name: str, difficulty: float, col: str, extractor: Callable = None):\n",
    "        self.col = col\n",
    "        self.extractor = extractor\n",
    "        if extractor is None:\n",
    "            extractor = lambda x: x\n",
    "        values = df[col].apply(extractor)\n",
    "        altcol = col + \"_alt\"\n",
    "        self.alt_col = altcol\n",
    "        alt_values = None\n",
    "        if self.alt_col in list(df.columns):\n",
    "            data = pd.concat([df, values], axis=1)\n",
    "            alt_values = data.apply(lambda row: list(sorted({extractor(x) for x in row[altcol]}.difference(row[col]))), axis=1)\n",
    "#                 print(alt_values[alt_values.apply(len) > 0])\n",
    "        super().__init__(key, name, difficulty, values, alt_values)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"NominalCategory('{self.key}', {len(self.sets)} values)\"\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.key < other.key\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.key == other.key\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.key)\n",
    "\n",
    "@total_ordering\n",
    "class MultiNominalCategory(Category):\n",
    "    def __init__(self, df: pd.DataFrame, key: str, name: str, difficulty: float, col: str):\n",
    "        values = df[col].apply(set).apply(sorted).apply(list)\n",
    "        altcol = col + \"_alt\"\n",
    "        alt_values = None\n",
    "        if altcol in list(df.columns):\n",
    "            alt_values = df.apply(lambda row: list(sorted(set(row[altcol]).difference(row[col]))), axis=1)\n",
    "        super().__init__(key, name, difficulty, values, alt_values)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"MultiNominalCategory('{self.key}', {len(self.sets)} values)\"\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.key < other.key\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.key == other.key\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.key)\n",
    "    \n",
    "        \n",
    "nominal_categories = [\n",
    "    NominalCategory(df, key=\"continent\", name=\"Continent\", difficulty=1, col=\"continent\"),\n",
    "    NominalCategory(df, key=\"starting_letter\", name=\"Starting letter\", difficulty=1, col=\"name\", extractor=lambda x: x[0].upper()),\n",
    "    NominalCategory(df, key=\"ending_letter\", name=\"Ending letter\", difficulty=2, col=\"name\", extractor=lambda x: x[-1].upper()),\n",
    "    NominalCategory(df, key=\"capital_starting_letter\", name=\"Capital starting letter\", difficulty=1.5, col=\"capital\", extractor=lambda x: x[0].upper()),\n",
    "    NominalCategory(df, key=\"capital_ending_letter\", name=\"Capital ending letter\", difficulty=3, col=\"capital\", extractor=lambda x: x[-1].upper()),\n",
    "    MultiNominalCategory(df, key=\"flag_colors\", name=\"Flag color\", difficulty=1.5, col=\"flag_colors\"),\n",
    "]\n",
    "nominal_categories = {cat.key: cat for cat in nominal_categories}\n",
    "\n",
    "values = pd.concat([\n",
    "    df[[\"iso\", \"name\"]],\n",
    "    pd.DataFrame({cat.key: cat.values for cat in nominal_categories.values()}),\n",
    "    pd.DataFrame({cat.alt_key: cat.alt_values for cat in nominal_categories.values() if cat.alt_values is not None}),\n",
    "#     pd.DataFrame(bool_categories)\n",
    "], axis=1)\n",
    "\n",
    "values[values[[cat.alt_key for cat in nominal_categories.values()]].applymap(len).sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Ideas\n",
    "\n",
    "- Starting/ending with letter\n",
    "- Capital starting/ending with letter\n",
    "- Top/Bottom 20 (area/population)\n",
    "- (dynamic): Bigger/smaller/More/less populated than X\n",
    "- Island?\n",
    "- Landlocked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_categories = {\n",
    "#     \"Island\": df[\"neighbours\"].apply(lambda x: not x),\n",
    "#     \"Landlocked\": None,\n",
    "#     \"Top 10 Area\": df.ISO.isin(df.nlargest(10, 'Area(in sq km)').ISO),\n",
    "#     \"Bottom 10 Area\": df.ISO.isin(df.nsmallest(10, 'Area(in sq km)').ISO),\n",
    "#     \"Top 10 Pop.\": df.ISO.isin(df.nlargest(10, 'Population').ISO),\n",
    "#     \"Bottom 10 Pop.\": df.ISO.isin(df.nsmallest(10, 'Population').ISO),\n",
    "# }\n",
    "# values = pd.concat([df[[\"ISO\", \"Country\"]], pd.DataFrame(nominal_categories), pd.DataFrame(bool_categories)], axis=1)\n",
    "# values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cat in nominal_categories.values():\n",
    "    if isinstance(cat, NominalCategory):\n",
    "        cat.sets = values.groupby(by=cat.key)[\"iso\"].agg(sorted)\n",
    "        cat.alt_sets = values.explode(column=cat.alt_key).groupby(by=cat.alt_key)[\"iso\"].agg(sorted)\n",
    "    elif isinstance(cat, MultiNominalCategory):\n",
    "        cat.sets = values.explode(column=cat.key).groupby(by=cat.key)[\"iso\"].agg(sorted)\n",
    "        cat.alt_sets = values.explode(column=cat.alt_key).groupby(by=cat.alt_key)[\"iso\"].agg(sorted)\n",
    "\n",
    "while True:\n",
    "    # Retain only sets with at least 3 (FIELD_SIZE) elements\n",
    "    num_sets_0 = sum(len(cat.sets) for cat in nominal_categories.values())\n",
    "    for cat in nominal_categories.values():\n",
    "        cat.sets = cat.sets[cat.sets.apply(len) >= FIELD_SIZE]\n",
    "    num_sets_1 = sum(len(cat.sets) for cat in nominal_categories.values())\n",
    "    if num_sets_0 != num_sets_1:\n",
    "        print(f\"Removed {num_sets_0 - num_sets_1} category sets\")\n",
    "    # Retain only countries contained in sets of at least 2 different categories (-> has matching row+column)\n",
    "    category_contents = {cat.key: cat.sets.sum() for cat in nominal_categories.values()}\n",
    "    # {cat: len(cc) for cat, cc in category_contents.items()}\n",
    "    contents = set().union(*[set(cc) for cc in category_contents.values()])\n",
    "    print(\"contents:\", len(contents))\n",
    "    retain = {c for c in contents if len([key for key, cc in category_contents.items() if c in cc]) >= 2}\n",
    "    print(\"retain:\", len(retain))\n",
    "    remove = contents.difference(retain)\n",
    "    \n",
    "    for cat in nominal_categories.values():\n",
    "        cat.sets = cat.sets.apply(lambda cc: [c for c in cc if c in retain])\n",
    "    if not remove:\n",
    "        break\n",
    "    print(f\"Removed {len(remove)} countries:\", remove)\n",
    "    print(\"Repeat ...\")\n",
    "\n",
    "list(nominal_categories.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sets(set1, set2):\n",
    "    if len(set1) < len(set2):\n",
    "        return -1\n",
    "    if len(set1) > len(set2):\n",
    "        return 1\n",
    "    l1 = list(sorted(set(set1)))\n",
    "    l2 = list(sorted(set(set2)))\n",
    "    if l1 < l2:\n",
    "        return -1\n",
    "    if l1 > l2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def min_set(set1, set2):\n",
    "    cmp = compare_sets(set1, set2)\n",
    "    return set2 if cmp > 0 else set1\n",
    "\n",
    "def max_set(set1, set2):\n",
    "    cmp = compare_sets(set1, set2)\n",
    "    return set2 if cmp < 0 else set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfv = pd.concat([pd.DataFrame({\"iso\": values[\"iso\"], \"category\": cat.key, \"value\": values[cat.key], \"alt_values\": values[cat.alt_key]}) for cat in nominal_categories.values()], ignore_index=True)\n",
    "# dfv[\"category_type\"] = dfv[\"category\"].apply(lambda key: nominal_categories[key].__class__.__name__)\n",
    "\n",
    "# def merge_values(row):\n",
    "#     if row[\"category_type\"] == \"NominalCategory\":\n",
    "#         return [row[\"value\"]] + row[\"alt_values\"]\n",
    "#     if row[\"category_type\"] == \"MultiNominalCategory\":\n",
    "#         return row[\"value\"] + row[\"alt_values\"]\n",
    "#     return []\n",
    "# dfv[\"all_values\"] = dfv.apply(merge_values, axis=1)\n",
    "# dfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "setkeys = sum([[(cat.key, value) for value in cat.sets.index] for cat in nominal_categories.values()], [])\n",
    "\n",
    "def is_cell_allowed(key1, value1, key2, value2):\n",
    "    if key1 != key2:\n",
    "        return True\n",
    "    cat = nominal_categories[key1]\n",
    "    if value1 == value2:\n",
    "        return False\n",
    "    return isinstance(cat, MultiNominalCategory)\n",
    "\n",
    "def init_cell_contents(key1, value1, key2, value2, alt=False):\n",
    "    cat1, cat2 = nominal_categories[key1], nominal_categories[key2]\n",
    "    contents = set(cat1.sets[value1]).intersection(cat2.sets[value2])\n",
    "    if not alt:\n",
    "        return sorted(contents)\n",
    "    \n",
    "    # Solutions caused by alternative values\n",
    "    all1 = set(cat1.sets[value1] + cat1.alt_sets.get(value1, []))\n",
    "    all2 = set(cat2.sets[value2] + cat2.alt_sets.get(value2, []))\n",
    "    alt_contents = all1.intersection(all2).difference(contents)\n",
    "    if not alt_contents:\n",
    "        return []\n",
    "    \n",
    "    # Prevent that two different alternative values are used to create a solution\n",
    "    # (e.g. Capital starting with P and ending with N -> South Africa - because of [P]retoria and Cape Tow[n])\n",
    "    if isinstance(cat1, NominalCategory) and isinstance(cat2, NominalCategory):\n",
    "        if cat1.col == cat2.col and cat1.extractor and cat2.extractor:\n",
    "            col = cat1.col\n",
    "            altcol = cat1.alt_col\n",
    "            dfx = df[df[\"iso\"].isin(alt_contents)][[\"iso\", col, altcol]].copy()\n",
    "            dfx[\"values\"] = dfx.apply(lambda row: [row[col]] + list(row[altcol]), axis=1)\n",
    "            dfx[\"src1\"] = dfx[\"values\"].apply(lambda xx: [x for x in xx if cat1.extractor(x) == value1])\n",
    "            dfx[\"src2\"] = dfx[\"values\"].apply(lambda xx: [x for x in xx if cat2.extractor(x) == value2])\n",
    "            dfx[\"keep\"] = dfx.apply(lambda row: not set(row[\"src1\"]).isdisjoint(row[\"src2\"]), axis=1)\n",
    "            alt_contents = dfx[dfx[\"keep\"]][\"iso\"].tolist()\n",
    "            \n",
    "#             print(f\"{key1}/{value1} - {key2}/{value2}\")\n",
    "#             display(dfx)\n",
    "#             print(f\"keep {alt_contents}\")\n",
    "    \n",
    "    return sorted(set(alt_contents))\n",
    "\n",
    "\n",
    "cells = {(min_set(row, col), max_set(row, col)): init_cell_contents(*row, *col)\n",
    "         for row, col in itertools.combinations(setkeys, 2) if is_cell_allowed(*row, *col)}\n",
    "\n",
    "print(f\"Generated {len(cells)} cells\")\n",
    "\n",
    "# Bring cells to DataFrame to do filtering (cell size etc.)\n",
    "cell_info = pd.DataFrame([{\"row_cat\": row[0], \"row_val\": row[1],\n",
    "                           \"col_cat\": col[0], \"col_val\": col[1],\n",
    "                           \"contents\": contents, \"alt_contents\": init_cell_contents(*row, *col, alt=True)} for (row, col), contents in cells.items()])\n",
    "cell_info[\"size\"] = cell_info[\"contents\"].apply(len)\n",
    "\n",
    "# display(cell_info[cell_info[\"row_cat\"] == cell_info[\"col_cat\"]])\n",
    "\n",
    "# cell_info[\"size\"].value_counts()\n",
    "cell_info = cell_info[(cell_info[\"size\"] >= MIN_CELL_SIZE) & (cell_info[\"size\"] <= MAX_CELL_SIZE)]\n",
    "plt.hist(cell_info[\"size\"], rwidth=.9, bins=[x-.5 for x in range(cell_info[\"size\"].min(), cell_info[\"size\"].max() + 1)])\n",
    "plt.title(\"Distribution of cell sizes\")\n",
    "\n",
    "# Bring back to dict with tuple access\n",
    "cell_keys = cell_info.apply(lambda row: ((row[\"row_cat\"], row[\"row_val\"]), (row[\"col_cat\"], row[\"col_val\"])), axis=1)\n",
    "cells = {key: (contents, alt_contents) for key, contents, alt_contents in zip(cell_keys, cell_info[\"contents\"], cell_info[\"alt_contents\"])}\n",
    "\n",
    "print(f\"Retained {len(cells)} cells (of size {MIN_CELL_SIZE}-{MAX_CELL_SIZE})\")\n",
    "# cell_info[cell_info[\"alt_contents\"].apply(len) > 0].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_info[cell_info.apply(lambda row: len({row[\"row_cat\"], row[\"col_cat\"]}.intersection([\"capital_starting_letter\", \"capital_ending_letter\"])) == 2, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_label(cat: Category, value):\n",
    "    if cat.key == \"continent\":\n",
    "        continents = {\"AF\": \"Africa\", \"EU\": \"Europe\", \"AS\": \"Asia\", \"NA\": \"N. America\", \"SA\": \"S. America\", \"OC\": \"Oceania\"}\n",
    "        return continents[value]\n",
    "    return f\"{cat.name}: {value}\"\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, values, solutions, alt_solutions, rows, cols):\n",
    "        self.size = FIELD_SIZE\n",
    "        self.values = values  # All possible values to be guessed (list of dicts)\n",
    "        self.solutions = solutions  # 3x3 array containing list of possible solutions\n",
    "        self.alt_solutions = alt_solutions  # 3x3 array containing list of possible alternative solutions\n",
    "        self.rows = rows  # rows (tuples of form (Category, value))\n",
    "        self.cols = cols  # columns (as above)\n",
    "    \n",
    "    def to_json(self, include_values=False):\n",
    "        data = {\n",
    "            \"size\": self.size,\n",
    "            \"solutions\": [[list(cell) for cell in row] for row in self.solutions],\n",
    "            \"alternativeSolutions\": [[list(cell) for cell in row] for row in self.alt_solutions],\n",
    "            \"labels\": {\n",
    "                \"rows\": [get_label(cat, value) for cat, value in self.rows],\n",
    "                \"cols\": [get_label(cat, value) for cat, value in self.cols]\n",
    "            }\n",
    "        }\n",
    "        if include_values:\n",
    "            data[\"values\"] = self.values\n",
    "        return data\n",
    "    \n",
    "    def to_dataframe(self, solution=False):\n",
    "        game_df = pd.DataFrame(data=[[\",\".join(c1) + (\",(\" + \",\".join(c2) + \")\" if c2 else \"\") for c1, c2 in zip(row1, row2)] for row1, row2 in zip(self.solutions, self.alt_solutions)] if solution else None,\n",
    "                               index=[get_label(cat, value) for cat, value in self.rows],\n",
    "                               columns=[get_label(cat, value) for cat, value in self.cols])\n",
    "        game_df.fillna(\"\", inplace=True)\n",
    "        return game_df\n",
    "\n",
    "\n",
    "def get_solutions(cells, row, col, alt=False):\n",
    "    i = 1 if alt else 0\n",
    "    if (row, col) in cells:\n",
    "        return cells[(row, col)][i]\n",
    "    if (col, row) in cells:\n",
    "        return cells[(col, row)][i]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample possible game setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_values = values[[\"iso\", \"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constraint:\n",
    "    def __init__(self, prop, num, mode):\n",
    "        # prop: function mapping a set (cat key, value) to some boolean value\n",
    "        # num: number of categories\n",
    "        # mode: -1: at most *num* matching categories. 0: exactly *num* matching categories. 1: at least *num* categories\n",
    "        self.prop = prop\n",
    "        self.num = num\n",
    "        self.mode = mode\n",
    "        \n",
    "    def match(self, key, value):\n",
    "        return self.prop(key, value)\n",
    "        \n",
    "    def count(self, sets):\n",
    "        return len([(key, value) for key, value in sets if self.match(key, value)])\n",
    "        \n",
    "    def balance(self, sets):\n",
    "        # (\"needs x more\", \"only x more allowed\")\n",
    "        n = self.count(sets)\n",
    "        return (self.num - n if self.mode >= 0 else None,\n",
    "                self.num - n if self.mode <= 0 else None)\n",
    "        \n",
    "    def apply(self, sets):\n",
    "        n = self.count(sets)\n",
    "        if self.mode == -1:\n",
    "            return n <= self.num\n",
    "        if self.mode == 0:\n",
    "            return n == self.num\n",
    "        return n >= self.num\n",
    "    \n",
    "    def is_once(self):\n",
    "        return n == 1 and self.mode == 0\n",
    "    \n",
    "    def is_never(self):\n",
    "        return n == 0 and self.mode == 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def category(key, n, mode):\n",
    "        return Constraint(lambda k, _: k == key, n, mode)\n",
    "    \n",
    "    @staticmethod\n",
    "    def exactly(prop, n):\n",
    "        return Constraint(prop, n, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def at_most(prop, n):\n",
    "        return Constraint(prop, n, -1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def at_least(prop, n):\n",
    "        return Constraint(prop, n, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def category_exactly(key, n):\n",
    "        return Constraint.category(key, n, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def category_at_most(key, n):\n",
    "        return Constraint.category(key, n, -1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def category_at_least(key, n):\n",
    "        return Constraint.category(key, n, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def once(prop):\n",
    "        return Constraint.exactly(prop, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def never(prop, n):\n",
    "        return Constraint.exactly(prop, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def at_most_once(prop):\n",
    "        return Constraint.at_most(prop, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dummy():\n",
    "        return Constraint(lambda cat: True, 0, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def _get_allowed_sets(cross_sets, parallel_sets, constraints):\n",
    "    # Check constraint balances\n",
    "    balance = [c.balance(cross_sets + parallel_sets) for c in constraints]\n",
    "    underfed = [c for (a, b), c in zip(balance, constraints) if a is not None and a > 0]\n",
    "    overfed = [c for (a, b), c in zip(balance, constraints) if b == 0]\n",
    "#     print(f\"{len(cross_sets)} cross, {len(parallel_sets)} parallel, {len(underfed)} underfed, {len(overfed)} overfed\")\n",
    "    \n",
    "    # underfed: needs more. overfed: maximum is reached.\n",
    "    choice = setkeys\n",
    "    if underfed or overfed:\n",
    "        # Only take those sets that satisfy some underfed constraint\n",
    "        choice = [(key, value) for key, value in choice\n",
    "                  if (any(c.match(key, value) for c in underfed) or not underfed)\n",
    "                  and not any(c.match(key, value) for c in overfed)]\n",
    "    # Not 2 identical (cat, value) sets in the game\n",
    "    choice = set(choice).difference(cross_sets).difference(parallel_sets)\n",
    "    # Not 2 crossing identical categories, except MultiNominal, but then only 1 each\n",
    "    # Each category only allowed twice\n",
    "    cross_cats = Counter(cat for cat, value in cross_sets)\n",
    "    parallel_cats = Counter(cat for cat, value in parallel_sets)\n",
    "    choice = {(cat, value) for cat, value in choice\n",
    "              if (cat not in cross_cats and parallel_cats.get(cat, 0) <= 1)\n",
    "              or (isinstance(nominal_categories[cat], MultiNominalCategory) and cross_cats[cat] == 1 and cat not in parallel_cats)}\n",
    "    \n",
    "    return choice\n",
    "\n",
    "\n",
    "def _sample_fitting_set(cross_sets, parallel_sets, constraints):\n",
    "    \"\"\" Samples a new column (assuming cross_sets are the rows and parallel_sets the previous columns. Or the other way round) \"\"\"\n",
    "    choice = list(_get_allowed_sets(cross_sets, parallel_sets, constraints))\n",
    "    # Iterate all possible sets randomly until a fitting one is hit\n",
    "    random.shuffle(choice)\n",
    "    for c in choice:\n",
    "        if all(get_solutions(cells, c, crossing) for crossing in cross_sets):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _sample_game_setup(constraints):\n",
    "    rows, cols = [], []\n",
    "    for _ in range(FIELD_SIZE):\n",
    "        # Sample a new column, then a new row\n",
    "        new_col = _sample_fitting_set(cross_sets=rows, parallel_sets=cols, constraints=constraints)\n",
    "        if new_col is not None:\n",
    "            cols.append(new_col)\n",
    "        else:\n",
    "            return None, None\n",
    "        new_row = _sample_fitting_set(cross_sets=cols, parallel_sets=rows, constraints=constraints)\n",
    "        if new_row is not None:\n",
    "            rows.append(new_row)\n",
    "        else:\n",
    "            return None, None\n",
    "    if len(rows) != FIELD_SIZE or len(cols) != FIELD_SIZE:\n",
    "        return None\n",
    "    # Check constraints\n",
    "    if not all(c.apply(rows + cols) for c in constraints):\n",
    "        return None, None\n",
    "    return rows, cols\n",
    "\n",
    "def sample_game(constraints=[], shuffle=True):\n",
    "    MAX_TRIES = 100\n",
    "    rows, cols = None, None\n",
    "    for i in range(MAX_TRIES):\n",
    "        rows, cols = _sample_game_setup(constraints)\n",
    "        if rows is not None and cols is not None:\n",
    "            break\n",
    "    \n",
    "    if rows is None or cols is None:\n",
    "        print(f\"Could not create game setup ({MAX_TRIES} tries)\")\n",
    "        return None\n",
    "        \n",
    "    if shuffle:\n",
    "        random.shuffle(rows)\n",
    "        random.shuffle(cols)\n",
    "        if random.random() > .5:\n",
    "            rows, cols = cols, rows\n",
    "    \n",
    "    game = Game(values=country_values.to_dict(orient=\"records\"),\n",
    "                solutions=[[get_solutions(cells, row, col) for col in cols] for row in rows],\n",
    "                alt_solutions=[[get_solutions(cells, row, col, alt=True) for col in cols] for row in rows],\n",
    "                rows=[(nominal_categories[cat], value) for cat, value in rows],\n",
    "                cols=[(nominal_categories[cat], value) for cat, value in cols])\n",
    "    game.i = i\n",
    "    return game\n",
    "\n",
    "constraints = [\n",
    "    # We always want a continent\n",
    "    Constraint.category_at_least(\"continent\", 1),\n",
    "    \n",
    "    # Some categories are pretty boring to appear multiple times\n",
    "    Constraint.category_at_most(\"capital_ending_letter\", 1),\n",
    "    Constraint.category_at_most(\"capital_starting_letter\", 1),\n",
    "    Constraint.category_at_most(\"ending_letter\", 1)\n",
    "]\n",
    "\n",
    "games = [sample_game(constraints=constraints, shuffle=False) for _ in range(1000)]\n",
    "\n",
    "for game in games[:10]:\n",
    "    print(game.i)\n",
    "    display(game.to_dataframe(solution=True))\n",
    "# get_allowed_sets([('capital_ending_letter', 'T'), ('flag_colors', 'Red'), ('starting_letter', 'T')], [('capital_starting_letter', 'O')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = [\n",
    "    # We always want a continent\n",
    "    Constraint.category_at_least(\"continent\", 1),\n",
    "    \n",
    "    # Some categories are pretty boring to appear multiple times\n",
    "    Constraint.category_at_most(\"capital_ending_letter\", 1),\n",
    "    Constraint.category_at_most(\"capital_starting_letter\", 1),\n",
    "    Constraint.category_at_most(\"ending_letter\", 1)\n",
    "]\n",
    "\n",
    "games = [sample_game(constraints=constraints, shuffle=False) for _ in range(1000)]\n",
    "\n",
    "SAVE = False\n",
    "\n",
    "if SAVE:\n",
    "    json.dump([game.to_json() for game in games], open(\"games.json\", mode=\"w\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in games:\n",
    "    if sum(sum(game.alt_solutions, []), []):\n",
    "        \n",
    "        display(game.to_dataframe(solution=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
